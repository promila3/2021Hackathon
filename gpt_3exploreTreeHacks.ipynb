{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-3exploreTreeHacks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "heIf5_ducY8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5485bf34-f411-4faa-99ec-790088cf7517"
      },
      "source": [
        "!pip install openai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/91/070425a1983c1a73b9a6186b28ac06ae87e619fff05257e4ae9b8078f26f/openai-0.3.0.tar.gz (157kB)\n",
            "\r\u001b[K     |██                              | 10kB 11.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 30kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 133kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 153kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->openai) (2020.12.5)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.3.0-cp36-none-any.whl size=171252 sha256=2907df36f32ad61c685926d4a7f0ced92b8f24a4978fd39f472a43151f70b2c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/75/b3/519250ae7ef404a76542edfbb7a290c78ebb314c5b8924f541\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIObOT-ybumY"
      },
      "source": [
        "import json\n",
        "import openai"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m42z9jQxqA2b"
      },
      "source": [
        "with open('gptapi.json') as f:\n",
        "    data = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75Yg2gB7p3Q0"
      },
      "source": [
        "openai.api_key = data[\"apikey\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnSe5H8lcvdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d5da19-c3a8-4945-fd97-52f1d3183ef7"
      },
      "source": [
        "openai.Engine.list()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7fd480f41d58> JSON: {\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"content-filter-alpha-c4\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"content-filter-dev\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-instruct-beta\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"cursing-filter-v6\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-instruct-beta\",\n",
              "      \"max_replicas\": null,\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true,\n",
              "      \"ready_replicas\": null,\n",
              "      \"replicas\": null\n",
              "    }\n",
              "  ],\n",
              "  \"object\": \"list\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3sAHxJrhBzK"
      },
      "source": [
        "from openai import *\n",
        "#from gpt import Example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbficzn7d4Iq"
      },
      "source": [
        "def gpt3(prompt, engine='davinci-instruct-beta', response_length=64,\r\n",
        "         temperature=0.7, top_p=1, frequency_penalty=0, presence_penalty=0,\r\n",
        "         start_text='', restart_text='', stop_seq=[]):\r\n",
        "    response = openai.Completion.create(\r\n",
        "        prompt=prompt + start_text,\r\n",
        "        engine=engine,\r\n",
        "        max_tokens=response_length,\r\n",
        "        temperature=temperature,\r\n",
        "        top_p=top_p,\r\n",
        "        frequency_penalty=frequency_penalty,\r\n",
        "        presence_penalty=presence_penalty,\r\n",
        "        stop=stop_seq,\r\n",
        "    )\r\n",
        "    answer = response.choices[0]['text']\r\n",
        "    new_prompt = prompt + start_text + answer + restart_text\r\n",
        "    return answer, new_prompt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcKJRZkZglh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381c6d9f-3c3f-42c1-801b-8219a08895fc"
      },
      "source": [
        "answer, prompt = gpt3('How big is the real estate market in San Francisco\\n', stop_seq=['\\n'])\r\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-NxQOG2iiTO"
      },
      "source": [
        "def chat():\r\n",
        "    prompt = \"\"\"Human: Hey, how are you doing?\r\n",
        "AI: I'm good! What would you like to chat about?\r\n",
        "Human:\"\"\"\r\n",
        "    while True:\r\n",
        "        prompt += input('You: ')\r\n",
        "        answer, prompt = gpt3(prompt,\r\n",
        "                              temperature=0.9,\r\n",
        "                              frequency_penalty=1,\r\n",
        "                              presence_penalty=1,\r\n",
        "                              start_text='\\nAI:',\r\n",
        "                              restart_text='\\nHuman: ',\r\n",
        "                              stop_seq=['\\nHuman:', '\\n'])\r\n",
        "        print('GPT-3:' + answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1SNYt1silEY"
      },
      "source": [
        "chat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiV0D9PihB2N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "4e4ed716-b033-477a-af52-7bacd87066c6"
      },
      "source": [
        "gpt = GPT(engine=\"davinci\",\n",
        "          temperature=0.5,\n",
        "          max_tokens=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b17ba3c943c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gpt = GPT(engine=\"davinci\",\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           max_tokens=100)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GPT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwVcHYMOvGiU"
      },
      "source": [
        "# Adding Examples for GPT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iLR1Y6YqTh7"
      },
      "source": [
        "gpt.add_example(Example('Fetch unique values of DEPARTMENT from Worker table.', \n",
        "                        'Select distinct DEPARTMENT from Worker;'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x28YlU1-qrCW"
      },
      "source": [
        "gpt.add_example(Example('Print the first three characters of FIRST_NAME from Worker table.', \n",
        "                        'Select substring(FIRST_NAME,1,3) from Worker;'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C10LyYPqrFX"
      },
      "source": [
        "gpt.add_example(Example(\"Find the position of the alphabet ('a') in the first name column 'Amitabh' from Worker table.\", \n",
        "                        \"Select INSTR(FIRST_NAME, BINARY'a') from Worker where FIRST_NAME = 'Amitabh';\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JvjODWbsBWP"
      },
      "source": [
        "gpt.add_example(Example(\"Print the FIRST_NAME from Worker table after replacing 'a' with 'A'.\", \n",
        "                        \"Select CONCAT(FIRST_NAME, ' ', LAST_NAME) AS 'COMPLETE_NAME' from Worker;\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNsH4OeqsKjM"
      },
      "source": [
        "gpt.add_example(Example(\"Display the second highest salary from the Worker table.\", \n",
        "                        \"Select max(Salary) from Worker where Salary not in (Select max(Salary) from Worker);\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhXh5g-jsKnl"
      },
      "source": [
        "gpt.add_example(Example(\"Display the highest salary from the Worker table.\", \n",
        "                        \"Select max(Salary) from Worker;\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWjmZe-Ntexm"
      },
      "source": [
        "gpt.add_example(Example(\"Fetch the count of employees working in the department Admin.\", \n",
        "                        \"SELECT COUNT(*) FROM worker WHERE DEPARTMENT = 'Admin';\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9xuF--Kt_xh"
      },
      "source": [
        "gpt.add_example(Example(\"Get all details of the Workers whose SALARY lies between 100000 and 500000.\", \n",
        "                        \"Select * from Worker where SALARY between 100000 and 500000;\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5jRwDCcuauE"
      },
      "source": [
        "gpt.add_example(Example(\"Get Salary details of the Workers\", \n",
        "                        \"Select Salary from Worker\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mI7FmwSu9AA"
      },
      "source": [
        "# Example 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWSmXABfrdTm"
      },
      "source": [
        "prompt = \"Display the lowest salary from the Worker table.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVzvJtmRqTku"
      },
      "source": [
        "output = gpt.submit_request(prompt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niqyIPAyoLQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "853cd2a0-ec4e-4454-90b8-cb8be70b0d4f"
      },
      "source": [
        "output.choices[0].text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'output: Select min(Salary) from Worker;\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA3DyhGJu_8o"
      },
      "source": [
        "# Example 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OdI6bFLtpel"
      },
      "source": [
        "prompt = \"Tell me the count of employees working in the department HR.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnjQ0kfbtpkE"
      },
      "source": [
        "output = gpt.submit_request(prompt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9Yo-bZotph4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e1572e6-bceb-42c8-d67f-4f29a156745c"
      },
      "source": [
        "output.choices[0].text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"output: SELECT COUNT(*) FROM worker WHERE DEPARTMENT = 'HR';\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnB7TCA_vCkF"
      },
      "source": [
        "# Example 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkaHZLIzt3pQ"
      },
      "source": [
        "prompt = \"Get salary details of the Workers whose AGE lies between 25 and 35\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6GmvbukmLCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "21c8f471-b272-47ed-dd18-36c94fbf6936"
      },
      "source": [
        "print(gpt.get_top_reply(prompt))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output: Select Salary from Worker where AGE between 25 and 35;\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZaLCw6zgqxh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}